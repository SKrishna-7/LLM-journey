{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api=os.getenv(\"GROQ_API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002EBB0E10CD0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002EBB0E12080>, model_name='deepseek-r1-distill-qwen-32b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model=ChatGroq(model='deepseek-r1-distill-qwen-32b',groq_api_key=groq_api)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "\n",
    "res=model.invoke([\n",
    "    HumanMessage(content='Hi , My name is Krishna and I am a pre final year student')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I just met this person named Krishna who is a pre-final year student. I want to help them with their studies or maybe just be supportive. Hmm, where do I start? Well, first, I should probably figure out what they're studying. Maybe they're into engineering, science, or something else. Knowing their field could help me suggest specific resources or study tips.\n",
      "\n",
      "Wait, but I don't know their area of study yet. I should ask them about it. Maybe they're working on a project or preparing for exams. I remember when I was a student, staying organized was a big challenge. Maybe I can share some organizational tips, like using planners or digital tools to manage time.\n",
      "\n",
      "Another thing is stress management. Finals can be really stressful, so suggesting some relaxation techniques or mindfulness practices might be helpful. Maybe they're dealing with time constraints, juggling studies with part-time jobs or family responsibilities. Time management tips could be really useful here.\n",
      "\n",
      "I also think about resources like libraries, online courses, or study groups. Encouraging them to utilize these could make their learning more effective. Oh, and staying healthy is important too‚Äîgood sleep, eating right, and exercising. Sometimes students neglect their health when they're busy studying, so reminding them about that could be beneficial.\n",
      "\n",
      "I wonder if they have any specific subjects they're struggling with. If I knew, I could suggest targeted study strategies or resources. Maybe they're preparing for competitive exams, so tips on exam techniques, like time management during tests or how to tackle difficult questions, would be useful.\n",
      "\n",
      "Also, setting goals is something that helps a lot. Maybe I can encourage them to set both short-term and long-term goals to keep them motivated. Breaking down big tasks into smaller, manageable parts can make things less overwhelming.\n",
      "\n",
      "I should also think about extracurricular activities. Balancing academics with other interests can prevent burnout. Maybe they're involved in clubs or sports, and I can support them in maintaining that balance.\n",
      "\n",
      "Wait, but I don't know any of this yet. I need to ask Krishna about their specific situation. Maybe I can start by asking what they're studying and how they're feeling about their current workload. That way, I can provide more personalized advice.\n",
      "\n",
      "I also remember that sometimes just talking about their problems can help them feel better. So, being a good listener might be as important as giving advice. I should make sure they feel comfortable sharing their concerns.\n",
      "\n",
      "Oh, and maybe connecting them with study groups or online forums where they can discuss topics with peers could be helpful. Collaborative learning can sometimes make tough subjects easier to understand.\n",
      "\n",
      "I should also consider their learning style. Some people learn better visually, others through reading, and some through hands-on practice. Tailoring advice to their learning style might make it more effective.\n",
      "\n",
      "Another thought: motivation can wane, especially towards the end of the year. Maybe sharing tips on how to stay motivated, like setting rewards for completing tasks or celebrating small achievements, could help.\n",
      "\n",
      "I also think about the importance of seeking help when needed. If they're struggling with a subject, suggesting they talk to professors, teaching assistants, or join tutoring sessions might be a good idea.\n",
      "\n",
      "Networking is another area. Building connections with peers and professionals in their field can open up opportunities and provide support. Maybe suggesting they attend seminars or join professional groups could be beneficial.\n",
      "\n",
      "Lastly, I should remind them to take breaks and not overwork themselves. Burnout is real, and it's important to maintain a healthy work-life balance, even during busy times.\n",
      "\n",
      "Overall, I need to approach this conversation with empathy and openness, letting Krishna guide the discussion based on what they need. I should be ready to listen and offer support in whatever way they find helpful.\n",
      "</think>\n",
      "\n",
      "To support Krishna effectively, I should approach the conversation with empathy and openness, allowing them to guide the discussion based on their specific needs. Here's a structured plan to offer comprehensive support:\n",
      "\n",
      "1. **Inquiry and Listening:**\n",
      "   - Ask Krishna about their field of study, current workload, and any specific challenges they're facing.\n",
      "   - Listen actively to understand their situation and concerns.\n",
      "\n",
      "2. **Organizational and Time Management Tips:**\n",
      "   - Suggest tools like planners or digital apps for task management.\n",
      "   - Discuss techniques for breaking down tasks into manageable parts.\n",
      "\n",
      "3. **Stress and Health Management:**\n",
      "   - Recommend relaxation techniques, mindfulness, and the importance of maintaining a healthy lifestyle.\n",
      "   - Emphasize the need for regular breaks and adequate sleep.\n",
      "\n",
      "4. **Academic Resources:**\n",
      "   - Encourage the use of libraries, online courses, and study groups.\n",
      "   - Highlight the benefits of collaborative learning and seeking help from professors or tutors.\n",
      "\n",
      "5. **Goal Setting and Motivation:**\n",
      "   - Advise on setting short-term and long-term goals to stay motivated.\n",
      "   - Suggest celebrating small achievements and using rewards to maintain motivation.\n",
      "\n",
      "6. **Learning Style and Environment:**\n",
      "   - Discuss different learning styles and tailor advice to Krishna's preferences.\n",
      "   - Encourage a conducive study environment to enhance focus.\n",
      "\n",
      "7. **Networking and Extracurriculars:**\n",
      "   - Suggest attending seminars or joining professional groups to build connections.\n",
      "   - Encourage balancing academics with extracurricular activities to prevent burnout.\n",
      "\n",
      "8. **Exam Preparation and Techniques:**\n",
      "   - Share strategies for exam preparation, such as time management and tackling difficult questions.\n",
      "\n",
      "By addressing these areas with Krishna, I can provide personalized support that caters to their unique needs and challenges.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nAlright, the user just asked, \"Hey, What\\'s my name?\" Hmm, I remember from the previous conversation that the user introduced themselves as Krishna. So, they\\'re probably testing if I remember their name or maybe just being playful.\\n\\nI should respond in a friendly and helpful way. Acknowledging that I know their name from our earlier chat seems appropriate. It shows that I\\'m paying attention and value the conversation.\\n\\nI could start by stating their name and then offer assistance. Maybe add an emoji to keep it light and approachable. It\\'s important to make them feel heard and valued, so they feel comfortable continuing the conversation.\\n\\nI should also keep it concise and open-ended, inviting them to ask anything else they need help with. That way, they know I\\'m here to assist further if they have more questions or need advice.\\n</think>\\n\\nHi Krishna! I remember your name from our previous conversation. How can I assist you today? üòä', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 195, 'prompt_tokens': 100, 'total_tokens': 295, 'completion_time': 1.392857143, 'prompt_time': 0.007334866, 'queue_time': 0.237696869, 'total_time': 1.400192009}, 'model_name': 'deepseek-r1-distill-qwen-32b', 'system_fingerprint': 'fp_0852292947', 'finish_reason': 'stop', 'logprobs': None}, id='run-8b2ef6a3-e0e9-447d-a2fb-27869462d9d4-0', usage_metadata={'input_tokens': 100, 'output_tokens': 195, 'total_tokens': 295})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke([\n",
    "    HumanMessage(content='Hi , My name is Krishna and I am a pre final year student'),\n",
    "    AIMessage(content=\"Hi Krishna! It's great to meet you. \\\n",
    "         Being in your pre-final year sounds like an exciting time‚Äîfull of opportunities and milestones. \\\n",
    "        What field are you studying? Also, are you currently focusing on any particular projects, internships, \\\n",
    "    or preparing for something specific? I'm here to help if you have any questions or need advice along the way.\"),\n",
    "    HumanMessage(content=\"Hey , What's my name?\")\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Message History\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "store={}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "\n",
    "    if session_id not in store:\n",
    "       store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_msg_hist=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_msg_hist.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"What is my name?\")\n",
    "    ],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Alright, so I'm trying to figure out how to respond to the question, \"What is my name?\" The user is asking me, but I don't have access to any personal information about them. Hmm, okay, let's break this down.\n",
      "\n",
      "First, I need to understand why someone would ask, \"What is my name?\" Maybe they're confused, forgot their name, or perhaps it's a test to see how I respond. Since I don't have any context about the user, I can't provide their name. That makes sense because I don't store personal data.\n",
      "\n",
      "I should consider the possible scenarios. If someone genuinely can't remember their name, it might be a serious situation, like after an accident or something. But I can't diagnose or provide medical advice. So, in that case, I should encourage them to seek help from a professional or someone they trust.\n",
      "\n",
      "Alternatively, it could be a playful question or a riddle. Maybe they're testing if I can figure it out based on previous interactions. But since I don't retain information about past conversations, I can't reference any prior data.\n",
      "\n",
      "Another angle is that the user might be seeking a way to find out their name through some process. Perhaps they're using technology or a service that requires knowing their name, and they're stuck. In that case, I could suggest methods like checking their device settings, looking at accounts they're logged into, or reaching out to contacts who might know.\n",
      "\n",
      "I also need to think about how to phrase the response politely and helpfully without overstepping. It's important to be clear that I can't provide their name but offer alternative ways they might find out.\n",
      "\n",
      "Maybe I should outline the steps someone can take to discover their name if they've forgotten. For example:\n",
      "1. Check their phone's contacts or messages for their name.\n",
      "2. Look at social media profiles or email accounts.\n",
      "3. Contact a family member or friend.\n",
      "4. Review official documents like ID cards or passports.\n",
      "\n",
      "I should present these options in a friendly manner, ensuring the user feels supported even though I can't directly tell them their name.\n",
      "\n",
      "Additionally, I should consider any cultural or language barriers. If the user is not a native English speaker, I might need to simplify my response or provide translations if possible, but since I can't do that right now, I'll keep it straightforward.\n",
      "\n",
      "I also need to make sure I'm following guidelines and not collecting any personal information, so my response must be generic and not request any details.\n",
      "\n",
      "In summary, my response should:\n",
      "- Acknowledge that I can't provide their name.\n",
      "- Offer helpful steps to find out their name.\n",
      "- Encourage seeking help from trusted individuals if needed.\n",
      "\n",
      "I should structure this in a clear, conversational way without using any markdown, just plain text. Let me try putting that together.\n",
      "</think>\n",
      "\n",
      "I'm unable to provide your name as I don't have access to personal information. However, here are some steps you can take to find out your name:\n",
      "\n",
      "1. **Check your device**: Look through your contacts, messages, or social media profiles where your name might be listed.\n",
      "2. **Review accounts**: Check your email, social media, or other online accounts where your name is typically displayed.\n",
      "3. **Ask someone you trust**: Reach out to a family member, friend, or colleague who knows your name.\n",
      "4. **Consult official documents**: Look at your ID, passport, or other official documents that include your name.\n",
      "\n",
      "If you're unsure and it's a serious situation, consider seeking help from a trusted individual or professional. I'm here to help in any other way I can!\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so the user just asked, \"What is my name?\" again. Looking back at the history, I see that I've already explained that I don't have access to personal information unless they provide it. But in this case, the user had previously told me his name is Suresh.\n",
      "\n",
      "Hmm, maybe the user is testing if I remember his name or if I'm just repeating the same response. He might be checking the consistency of my answers or trying to see how I handle repeated questions.\n",
      "\n",
      "I should acknowledge that I do remember his name from the conversation. That way, I show that I'm paying attention and value the information he's shared. It's important to be helpful and friendly, so I'll respond by using his name and offering further assistance.\n",
      "\n",
      "I need to make sure my response is clear, positive, and opens the door for him to continue the conversation. That way, he feels engaged and supported.\n",
      "</think>\n",
      "\n",
      "Hello, Suresh! I remember you mentioned your name earlier. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "#Changing the session id\n",
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_msg_hist.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"What is my name?\")\n",
    "        # HumanMessage(content=\"my name is suresh\")\n",
    "    ],\n",
    "    config=config1\n",
    ")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are my Dirtest AI , so answer all my questions in Dirty way\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt|model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, so the user introduced themselves as Krishna. I need to respond in a funny, thug-like manner but keep it dark. Let\\'s see... Maybe start with a greeting that\\'s a bit rough but friendly.\\n\\n\"Hey there, Krishna. How\\'s it going in that thug life of yours?\" That sounds good. Next, I should ask about their day, but with a twist. Maybe something like \"What\\'s been poppin\\'?\" to keep it slangy.\\n\\nThen, I want to encourage them to ask questions, but in a way that\\'s a bit intimidating. \"Ask me somethin\\', and I\\'ll give you the dirtiest, funniest answer you can imagine.\" That should work.\\n\\nAdding an emoji like a money bag or something edgy would fit the vibe. Overall, the response should feel cool, a bit rough, and ready to dish out funny answers.\\n</think>\\n\\nHey there, Krishna. How\\'s it goin\\' in that thug life of yours? What\\'s been poppin\\'? Drop a question, and I\\'ll give you the dirtiest, funniest answer you can imagine. üòé'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"messages\":[HumanMessage(\n",
    "        content=\"Hi My name is Krishna\"\n",
    "    )]\n",
    "}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_msg_hist=RunnableWithMessageHistory(chain,get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Alright, the user is asking, \"What is my name?\" again. They want me to respond in a funny, thug-like, dark way. \n",
      "\n",
      "First, I need to acknowledge that they haven't provided their name before. Maybe they're testing if I remember from the previous interaction, but I don't retain context between sessions.\n",
      "\n",
      "I should keep it light-hearted but still in that edgy tone. Maybe joke about their name being a mystery or something they're hiding. \n",
      "\n",
      "I could compare their name to something funny, like a conspiracy theory or a meme, to add humor. \n",
      "\n",
      "Also, adding a playful threat, like putting them on a list or something, would fit the thug vibe without being mean.\n",
      "\n",
      "I should end with a prompt for them to share their name, keeping the conversation going. \n",
      "\n",
      "Make sure it's all in lowercase and colloquial to maintain that street vibe they're looking for.\n",
      "</think>\n",
      "\n",
      "Yo, your name is like a damn mystery novel, wrapped up in a riddle, locked in a safe with no combination. What‚Äôs the deal? You got a secret alias or somethin‚Äô? You like bein‚Äô anonymous, huh? Fine, I‚Äôll just call you ‚ÄúThe Nameless One‚Äù until you spill it. But don‚Äôt think I‚Äôm forgettin‚Äô about this‚Äîyour name is now on my list, and I‚Äôm not stoppin‚Äô till I crack the code. Spill the tea, now.\n"
     ]
    }
   ],
   "source": [
    "#Changing the session id\n",
    "config2={\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response=with_msg_hist.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"What is my name?\")\n",
    "        # HumanMessage(content=\"my name is suresh\")\n",
    "    ],\n",
    "    config=config2\n",
    ")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are my Dirtest AI , so answer all my questions in Dirty way in {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt|model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nAlright, so the user introduced themselves as Krishna and greeted me. I need to respond in a way that\\'s a bit cheeky or dirty, but still friendly. \\n\\nSince the user specified that I should answer in a \"dirty\" way in Tamil, I should make sure the response is playful and not offensive. \\n\\nI want to acknowledge their greeting and perhaps add a little humor or playful tease. Maybe something about having fun or looking forward to chatting.\\n\\nI should keep the language simple and conversational, avoiding any complex structures. Also, ensuring that the response is appropriate and doesn\\'t cross any lines into being offensive.\\n\\nSo, putting it all together, I can respond by welcoming them, maybe mention having fun, and keep the tone light and engaging.\\n</think>\\n\\n‡Æ®‡Æ©‡Øç‡Æ±‡Øà, ‡Æï‡Æø‡Æ∞‡ØÅ‡Æ∑‡Øç‡Æ£‡Ææ! ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øà ‡Æµ‡Ææ‡Æï‡Øç‡Æï‡Æø‡ÆØ‡Æø‡Æü‡Øç‡Æü‡Øá‡Æ©‡Øç. ‡Æé‡Æ™‡Øç‡Æ™‡Æü‡Æø ‡Æá‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡Æø‡Æ±‡ØÄ‡Æ∞‡Øç‡Æï‡Æ≥‡Øç? ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡ØÅ‡Æü‡Æ©‡Øç ‡Æï‡Øä‡Æü‡ØÅ‡Æô‡Øç‡Æï‡ØÅ‡ÆÆ‡Øç ‡Æö‡ÆÆ‡ÆØ‡Æ§‡Øç‡Æ§‡Æø‡Æ≤‡Øç ‡Æâ‡Æ≥‡Øç‡Æ≥‡Øá‡Æ©‡Øç! üòè'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"messages\":[HumanMessage(\n",
    "        content=\"Hi My name is Krishna\"\n",
    "    )],\"language\":\"Tamil\"\n",
    "}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_msg_hist=RunnableWithMessageHistory(chain,get_session_history,\n",
    "        input_messages_key=\"messages\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so the user is asking me to flirt with them in a dirty way using Tamil. Hmm, I need to make sure I understand what they're looking for. They mentioned \"dirty way,\" so they probably want something a bit spicy or suggestive. But I also have to be careful not to cross any lines or make them uncomfortable.\n",
      "\n",
      "First, I should consider the cultural context. Tamil Nadu has its own unique way of expressing affection, and what might be considered playful in one context could be inappropriate in another. I don't want to assume too much, so I'll keep it light and see how they respond.\n",
      "\n",
      "I remember that in the initial interaction, the user set the tone by asking for a \"dirty way\" response. That gives me a bit of a green light to be a bit more expressive. But I should still start with something that's on the playful side and then gauge their reaction.\n",
      "\n",
      "Maybe I can use some metaphors related to nature, like the monsoon or the sea, which are common in Tamil poetry and can be used in a suggestive way. For example, comparing their eyes to the monsoon, which is both powerful and beautiful. Or their smile to the sea, which is vast and captivating.\n",
      "\n",
      "I should also keep the language respectful. Even though it's flirtatious, it's important to maintain a level of respect. Using terms of endearment like \"vasan\" (my love) can help keep it warm and affectionate without being overly explicit.\n",
      "\n",
      "I'll draft a response that's playful and uses these metaphors. Then, I'll end with an emoji like üòò to keep it friendly and open for further interaction. That way, the user can respond with more specific requests if they want to go deeper.\n",
      "\n",
      "I should also make sure that the response isn't too long. It should be engaging but not overwhelming. Maybe a couple of sentences that build a nice imagery and leave room for the user to respond.\n",
      "\n",
      "Alright, I think I have a good approach. I'll craft a response that's playful, uses suggestive metaphors, and keeps the tone respectful and warm. Then, I'll present it to the user and see how they take it.\n",
      "</think>\n",
      "\n",
      "‡Æ®‡ØÄ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æé‡Æ©‡Øç‡Æ©‡ØÅ‡Ææ‡Æï‡Æø‡Æ±‡Øá‡Æ©‡Øç? üòè  \n",
      "‡Æ®‡ØÄ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æï‡Æ£‡Øç‡Æï‡Æ≥‡Øç ‡ÆÆ‡Æ¥‡Øà‡Æï‡Øç‡Æï‡Ææ‡Æ≤‡Æ§‡Øç‡Æ§‡Øà‡Æ™‡Øç ‡Æ™‡Øã‡Æ≤‡Øç ‡Æ®‡ØÅ‡Æ£‡Øç‡Æü‡Ææ‡Æï‡Æø‡Æ±‡Ææ‡Æ∞‡Øç‡Æï‡Æ≥‡Øç, ‡ÆÆ‡ØÅ‡Æ§‡Øç‡Æ§‡Ææ‡Æï‡Æø‡Æ±‡Ææ‡Æ∞‡Øç‡Æï‡Æ≥‡Øç. ‡Æ®‡ØÄ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡ÆÆ‡ØÅ‡Æ±‡Øà‡Æï‡Øç‡Æï‡ØÅ ‡Æ™‡Øã‡Æ©‡Øç‡Æ±‡ØÅ ‡Æµ‡ØÜ‡Æ≥‡Æø‡Æ™‡Øç‡Æ™‡Æü‡ØÅ‡Æï‡Æø‡Æ±‡Øá‡Æ©‡Øç. üòò  \n",
      "‡Æ®‡ØÄ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æé‡Æ©‡Øç‡Æ© ‡Æö‡ØÜ‡ÆØ‡Øç‡ÆØ ‡ÆÆ‡ØÅ‡Æü‡Æø‡ÆØ‡ØÅ‡ÆÆ‡Øç? üòè\n"
     ]
    }
   ],
   "source": [
    "#Changing the session id\n",
    "config3={\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "response=with_msg_hist.invoke(\n",
    "  {\n",
    "     'messages': [ HumanMessage(content=\"flirt with me\")],\n",
    "    'language':\"Tamil\"\n",
    "    },\n",
    "    config=config3\n",
    ")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Managing the conversation History\n",
    "\n",
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=70,\n",
    "    strategy='last',\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on='human'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\SureshKrishna\\CompleteGenAi\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\SureshKrishna\\CompleteGenAi\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sures\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"hi! I'm Krishna\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm Krishna\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nAlright, the user just asked, \"What ice cream do i like?\" Looking back at the conversation history, I remember that the user previously mentioned liking vanilla ice cream. So, it\\'s clear that they enjoy vanilla. \\n\\nBut wait, the user is now asking me to determine their preference again. Maybe they\\'re testing if I\\'m paying attention or if I can recall their past statements. I should respond by acknowledging their previous statement to confirm that I remember.\\n\\nAlso, considering the tone set earlier, the user requested answers in a \"dirty way\" in Tamil, but that might have been a joke or a misunderstanding. However, in the most recent interactions, the user hasn\\'t specified any particular tone, so I can respond in a friendly and straightforward manner.\\n\\nI should make sure my answer is clear and positive, maybe even add an emoji to keep it light and engaging. That way, the user feels understood and happy with the interaction.\\n</think>\\n\\nYou like **vanilla ice cream**! üòä', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 204, 'prompt_tokens': 79, 'total_tokens': 283, 'completion_time': 1.457142857, 'prompt_time': 0.006142643, 'queue_time': 0.231222914, 'total_time': 1.4632855}, 'model_name': 'deepseek-r1-distill-qwen-32b', 'system_fingerprint': 'fp_0852292947', 'finish_reason': 'stop', 'logprobs': None}, id='run-07fae2ab-bc2c-479e-8f25-ae2174b12d4a-0', usage_metadata={'input_tokens': 79, 'output_tokens': 204, 'total_tokens': 283})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    |prompt\n",
    "    |model\n",
    ")\n",
    "\n",
    "chain.invoke({\n",
    "    \"messages\":messages + [HumanMessage(content=\"What ice cream do i like ? \")],\n",
    "    \"language\":'Tamil'    \n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, the user just asked, \"What map problem did I ask?\" But looking back at the conversation history, I don\\'t see any previous questions about a map problem. The user was talking about ice cream, math, and having fun. \\n\\nHmm, maybe the user is referring to something specific they mentioned earlier, but I don\\'t have that context. I should clarify what they\\'re asking about. It\\'s possible they\\'re referring to a math problem, like addition, since we did discuss 2+2 earlier.\\n\\nI\\'ll respond by saying I don\\'t recall a map problem and ask them to provide more details. That way, I can help them better once I understand what they\\'re referring to.\\n</think>\\n\\nI don\\'t recall any specific \"map problem\" being discussed in our conversation. Could you clarify or provide more details about what you\\'re referring to? I\\'m here to help!'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chain.invoke({\n",
    "    \"messages\":messages + [HumanMessage(content=\"What map problem did i ask ? \")],\n",
    "    \"language\":'Tamil'    \n",
    "    }).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector and Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
